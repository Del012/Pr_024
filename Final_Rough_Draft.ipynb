{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Trump/Hillary Tweets\n",
    "### Question: \n",
    "\n",
    "What combination of words result in the highest amount of retweets? As in, are there a set of #N words that Trump or Hillary could tweet that garners the most retweets and likes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using Trump and Hillary Tweets before the 2016 Presidential Election and analyzing these two datasets to find the most common words that each respective candidates used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/trandonbay/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/trandonbay/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Basic packages to be used in the project. \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import string\n",
    "\n",
    "#Natural Language Toolkit\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#NLTK tokenizer for tweets.\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Cleaning the Data\n",
    "\n",
    "We are loading both the datasets so we can retrieve both Trump and Hillary tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dataframe of Trump tweets.\n",
    "df_trump = pd.read_csv('Trump_Tweets.csv', encoding='latin-1');\n",
    "\n",
    "#Dataframe of Hillary tweets.\n",
    "df_th = pd.read_csv('Trump_Hillary_Tweets.csv');\n",
    "df_hillary = df_th[df_th['handle'] == 'HillaryClinton'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleaned unnecessary columns of the Trump tweets.\n",
    "del df_trump['Unnamed: 10'];\n",
    "del df_trump['Unnamed: 11'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TESTING\n",
    "#df_trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TESTING\n",
    "#tweet = tknzr.tokenize(df_trump['Tweet_Text'][0])\n",
    "#tweet = words_stop(tweet)\n",
    "#tweet = words_only(tweet)\n",
    "#tweet = words_extra(tweet)\n",
    "#print(tweet);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Helper method to filter out stopwords.\n",
    "def words_stop(tweet_list):\n",
    "    punctuation = list(string.punctuation)\n",
    "    stop = stopwords.words('english') + punctuation + ['rt','via']\n",
    "    return [word for word in tweet_list if word not in stop]\n",
    "\n",
    "#Helper method to filter out hashtags and mentions.\n",
    "def words_only(tweet_list):\n",
    "    return [word for word in tweet_list if not word.startswith(('#','@','û','https'))]\n",
    "\n",
    "#Helper method to filter extra words.\n",
    "def words_extra(tweet_list):\n",
    "    extra = ['\\x89','...','…','“','”','’','—']\n",
    "    return [word for word in tweet_list if word not in extra]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parsing the Trump Tweets.\n",
    "\n",
    "We are parsing the Trump tweets, so we can create a frequency distribution of words contained in his tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#METHOD: Parse Trump tweets and create a frequency distribution of words.\n",
    "\n",
    "#Tokenizes the Trump tweets.\n",
    "trump_list = []\n",
    "for trump_tweets in df_trump['Tweet_Text']:\n",
    "    trump_list.extend(tknzr.tokenize(trump_tweets))\n",
    "\n",
    "#Filters the tweets.\n",
    "trump_list = words_stop(trump_list)\n",
    "trump_list = words_only(trump_list)\n",
    "trump_list = words_extra(trump_list)\n",
    "\n",
    "#Create the frequency distribution.\n",
    "fdist_t = nltk.FreqDist(trump_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 8573 samples and 63904 outcomes>\n"
     ]
    }
   ],
   "source": [
    "#print(fdist_t);\n",
    "#trump_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 1173),\n",
       " ('great', 1045),\n",
       " ('thank', 889),\n",
       " ('hillary', 543),\n",
       " ('america', 487),\n",
       " ('people', 443),\n",
       " ('new', 410),\n",
       " ('poll', 364),\n",
       " ('make', 346),\n",
       " ('donald', 321),\n",
       " ('clinton', 316),\n",
       " ('get', 305),\n",
       " ('president', 267),\n",
       " ('like', 266),\n",
       " ('big', 263),\n",
       " ('vote', 257),\n",
       " ('tonight', 244),\n",
       " ('time', 232),\n",
       " ('cruz', 228),\n",
       " ('one', 227)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_t.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parsing the Hillary Tweets.\n",
    "\n",
    "We are parsing the Hillary tweets, so we can create a frequency distribution of words contained in her tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tokenizes the Hillary tweets.\n",
    "hillary_list = []\n",
    "for hillary_tweets in df_hillary['text']:\n",
    "    hillary_list.extend(tknzr.tokenize(hillary_tweets))\n",
    "\n",
    "#Filters the tweets.\n",
    "hillary_list = words_stop(hillary_list)\n",
    "hillary_list = words_only(hillary_list)\n",
    "hillary_list = words_extra(hillary_list)\n",
    "\n",
    "#Create the frequency distribution.\n",
    "fdist_h = nltk.FreqDist(hillary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(fdist);\n",
    "#hillary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fdist_h.most_common(20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Dictionary of words with favourites and retweets.\n",
    "\n",
    "Create a dictionary with the words as the key and a tuple of retweets and favorites, unweighted. Then, weigh retweets more heavily by multiplying by the ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the ratio between favorites and retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio of trump favorites to retweet is:  2.5952112676056336\n",
      "The ratio of hillary favorites to retweet is:  2.245588632228205\n"
     ]
    }
   ],
   "source": [
    "sum_fav_t = df_trump['twt_favourites_IS_THIS_LIKE_QUESTION_MARK'].sum();\n",
    "sum_rtwt_t = df_trump['Retweets'].sum();\n",
    "\n",
    "sum_fav_h = df_hillary['favorite_count'].sum();\n",
    "sum_rtwt_h = df_hillary['retweet_count'].sum();\n",
    "\n",
    "trump_ratio = sum_fav_t/sum_rtwt_t\n",
    "hillary_ratio = sum_fav_h/sum_rtwt_h\n",
    "\n",
    "print('The ratio of trump favorites to retweet is: ', trump_ratio)\n",
    "print('The ratio of hillary favorites to retweet is: ', hillary_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Trump tweets dictionary.\n",
    "from collections import namedtuple\n",
    "Tweets = namedtuple('Tweets', 'favourites retweets')\n",
    "\n",
    "trump_dict = {}\n",
    "i = 0\n",
    "\n",
    "for trump_tweet in df_trump['Tweet_Text']:\n",
    "    \n",
    "    tweet = tknzr.tokenize(trump_tweet)\n",
    "    tweet = words_stop(tweet)\n",
    "    tweet = words_only(tweet)\n",
    "    tweet = words_extra(tweet)\n",
    "    \n",
    "    for word in tweet:\n",
    "        trump_dict.setdefault(word, Tweets(0, 0))\n",
    "        num_fav = df_trump['twt_favourites_IS_THIS_LIKE_QUESTION_MARK'][i]\n",
    "        num_rtwt = df_trump['Retweets'][i]\n",
    "        \n",
    "        fav = trump_dict[word].favourites + num_fav\n",
    "        rtwt = trump_dict[word].retweets + (num_rtwt*trump_ratio)\n",
    "        \n",
    "        trump_dict[word] = trump_dict[word]._replace(favourites = fav, retweets = rtwt)\n",
    "        \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweets(favourites=3654710, retweets=3608828.1228168998)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_dict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Hillary tweets dictionary.\n",
    "from collections import namedtuple\n",
    "Tweets = namedtuple('Tweets', 'favourites retweets')\n",
    "\n",
    "hillary_dict = {}\n",
    "i = 0\n",
    "\n",
    "for hillary_tweet in df_hillary['text']:\n",
    "    \n",
    "    tweet = tknzr.tokenize(hillary_tweet)\n",
    "    tweet = words_stop(tweet)\n",
    "    tweet = words_only(tweet)\n",
    "    tweet = words_extra(tweet)\n",
    "    \n",
    "    for word in tweet:\n",
    "        hillary_dict.setdefault(word, Tweets(0, 0))\n",
    "        num_fav = df_hillary['favorite_count'].iloc[i]\n",
    "        num_rtwt = df_hillary['retweet_count'].iloc[i]\n",
    "        \n",
    "        fav = hillary_dict[word].favourites + num_fav\n",
    "        rtwt = hillary_dict[word].retweets + (num_rtwt*hillary_ratio)\n",
    "        \n",
    "        hillary_dict[word] = hillary_dict[word]._replace(favourites = fav, retweets = rtwt)\n",
    "        \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweets(favourites=587221, retweets=595561.54350777133)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hillary_dict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Trump and Hillary dictionaries of reactions/frequency of the words.\n",
    "rxn_dict_t = {}\n",
    "rxn_dict_h = {}\n",
    "\n",
    "for k, v in trump_dict.items():\n",
    "    rxn_t = v.favourites + v.retweets\n",
    "    freq_t = fdist_t[k]\n",
    "    rxn_dict_t.setdefault(k, rxn_t/freq_t)\n",
    "    \n",
    "    \n",
    "for k, v in hillary_dict.items():\n",
    "    rxn_h = v.favourites + v.retweets\n",
    "    freq_h = fdist_h[k]\n",
    "    rxn_dict_h.setdefault(k, rxn_h/freq_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#((word.retweets * ratio) + word.favorites) / word.freq\n",
    "from collections import OrderedDict\n",
    "\n",
    "trump_rxnfreq = OrderedDict(sorted(rxn_dict_t.items(), key=lambda kv: kv[1], reverse=True))\n",
    "hillary_rxnfreq = OrderedDict(sorted(rxn_dict_h.items(), key=lambda kv: kv[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Most Frequently Used</th>\n",
       "      <th>Occurrences</th>\n",
       "      <th>Most Reacted To</th>\n",
       "      <th>Weighted Reactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump</td>\n",
       "      <td>1173</td>\n",
       "      <td>forensic</td>\n",
       "      <td>561665.396901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>1045</td>\n",
       "      <td>forgotten</td>\n",
       "      <td>428974.044178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thank</td>\n",
       "      <td>889</td>\n",
       "      <td>taco</td>\n",
       "      <td>304308.441690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hillary</td>\n",
       "      <td>543</td>\n",
       "      <td>bowls</td>\n",
       "      <td>304308.441690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>america</td>\n",
       "      <td>487</td>\n",
       "      <td>grill</td>\n",
       "      <td>304308.441690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>people</td>\n",
       "      <td>443</td>\n",
       "      <td>9:45</td>\n",
       "      <td>303221.350986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>new</td>\n",
       "      <td>410</td>\n",
       "      <td>corps</td>\n",
       "      <td>275065.159155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>poll</td>\n",
       "      <td>364</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>273712.110986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>make</td>\n",
       "      <td>346</td>\n",
       "      <td>melanias</td>\n",
       "      <td>223319.582160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>donald</td>\n",
       "      <td>321</td>\n",
       "      <td>incited</td>\n",
       "      <td>213800.665070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Most Frequently Used  Occurrences Most Reacted To  Weighted Reactions\n",
       "0                trump         1173        forensic       561665.396901\n",
       "1                great         1045       forgotten       428974.044178\n",
       "2                thank          889            taco       304308.441690\n",
       "3              hillary          543           bowls       304308.441690\n",
       "4              america          487           grill       304308.441690\n",
       "5               people          443            9:45       303221.350986\n",
       "6                  new          410           corps       275065.159155\n",
       "7                 poll          364       chemistry       273712.110986\n",
       "8                 make          346        melanias       223319.582160\n",
       "9               donald          321         incited       213800.665070"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Datafram of Trump word frequency vs. word reactions.\n",
    "df_common_t = pd.DataFrame(fdist_t.most_common(10))\n",
    "df_rxn_t = pd.DataFrame(list(trump_rxnfreq.items())[0:10])\n",
    "\n",
    "dfFreq_t = pd.concat([df_common_t,df_rxn_t],axis=1)\n",
    "\n",
    "dfFreq_t.columns = ['Most Frequently Used', 'Occurrences', 'Most Reacted To', 'Weighted Reactions']\n",
    "dfFreq_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Most Frequently Used</th>\n",
       "      <th>Occurrences</th>\n",
       "      <th>Most Reacted To</th>\n",
       "      <th>Weighted Reactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump</td>\n",
       "      <td>774</td>\n",
       "      <td>delete</td>\n",
       "      <td>1.761127e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hillary</td>\n",
       "      <td>708</td>\n",
       "      <td>silence</td>\n",
       "      <td>2.538532e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donald</td>\n",
       "      <td>427</td>\n",
       "      <td>poland</td>\n",
       "      <td>2.148997e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>president</td>\n",
       "      <td>279</td>\n",
       "      <td>account</td>\n",
       "      <td>2.064096e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>america</td>\n",
       "      <td>203</td>\n",
       "      <td>housekeeping</td>\n",
       "      <td>2.025102e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>people</td>\n",
       "      <td>195</td>\n",
       "      <td>so-called</td>\n",
       "      <td>2.020907e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>make</td>\n",
       "      <td>189</td>\n",
       "      <td>losers</td>\n",
       "      <td>2.020907e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>one</td>\n",
       "      <td>181</td>\n",
       "      <td>dummies</td>\n",
       "      <td>2.020907e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>us</td>\n",
       "      <td>174</td>\n",
       "      <td>tested</td>\n",
       "      <td>1.698351e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trump's</td>\n",
       "      <td>149</td>\n",
       "      <td>hi</td>\n",
       "      <td>1.624831e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Most Frequently Used  Occurrences Most Reacted To  Weighted Reactions\n",
       "0                trump          774          delete        1.761127e+06\n",
       "1              hillary          708         silence        2.538532e+05\n",
       "2               donald          427          poland        2.148997e+05\n",
       "3            president          279         account        2.064096e+05\n",
       "4              america          203    housekeeping        2.025102e+05\n",
       "5               people          195       so-called        2.020907e+05\n",
       "6                 make          189          losers        2.020907e+05\n",
       "7                  one          181         dummies        2.020907e+05\n",
       "8                   us          174          tested        1.698351e+05\n",
       "9              trump's          149              hi        1.624831e+05"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe of Hillary word frequency vs. word reactions.\n",
    "df_common_h = pd.DataFrame(fdist_h.most_common(10))\n",
    "df_rxn_h = pd.DataFrame(list(hillary_rxnfreq.items())[0:10])\n",
    "\n",
    "dfFreq_h = pd.concat([df_common_h,df_rxn_h],axis=1)\n",
    "\n",
    "dfFreq_h.columns = ['Most Frequently Used', 'Occurrences', 'Most Reacted To', 'Weighted Reactions']\n",
    "dfFreq_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make a histogram. (1-2 graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
