{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Assignment 4: Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important\n",
    "\n",
    "- Make sure all group member (3-5 people) are listed in the group members section.\n",
    "- ONE, and only one, member of your group should upload this notebook to TritonED. \n",
    "- Each member of the group will receive the same grade on this assignment. \n",
    "- Keep the file name the same: submit the file 'A4_ProjectProposal.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the project description, and detailed instructions for this assignment, in the 'A4_ProjectOutlineAndProposal' pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Members: Fill in the Student ID's of each group member here\n",
    "Michael Kim Sing - A99108090\n",
    "\n",
    "Benny Lee - A13592070\n",
    "\n",
    "Dennis Liu - A12117152\n",
    "\n",
    "Claire Huong Pham -  A11463888\n",
    "\n",
    "Cindy Perez - A12243634\n",
    "\n",
    "Brandon Tay - A11449995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question\n",
    "\n",
    "What is your research question? (1-2 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What combination of words result in the highest amount of retweets? As in, are there a set of #N words that Trump or Hillary could tweet that garners the most retweets and likes? We will look into what kind of words or sets of words generate the strongest reaction (in terms of retweets and likes) when tweeted by each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "\n",
    "What is your prediction (2-3 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe that Trump garners a higher amount of retweets and likes when he makes controversial, inflammatory statements (with regards to both campaign issues or regarding other candidates) or uses any of his common phrases such as ‘wall’, ‘china’,  and ‘make America great again’. Moreover, we believe that Hillary will likewise have similar success with her platform buzzwords such as ‘healthcare’, ‘women’s rights’ and ‘equality’. We expect to see a strong correlation with number of reactions and the controversial nature of a statement. Specifically, we will be defining a “reaction” as encompassing both negative and positive, since retweeting can be used as a means of both showing support and voicing disapproval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset(s)\n",
    "\n",
    "What data will you use to answer your question? Describe the dataset in terms of number of observations, what kind of features it contains, etc. You must use at least one dataset containing at least approximately 1000 observations (if your data are smaller but you feel they are sufficient, email Prof. Voytek). You are welcome (and in fact recommended) to find multiple datasets! If you do so, describe each one, and briefly explain how you will combine them together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your dataset information here*\n",
    "\n",
    "(Copy this information for each dataset)\n",
    "- Dataset Name: \n",
    "1.CrowdBabble_Social-Media-Analytics_Twitter-Download_Donald-Trump_7375-Tweets-Excel\n",
    "2.tweets.csv\n",
    "\n",
    "- Link to the dataset:\n",
    "1.https://www.crowdbabble.com/blog/the-11-best-tweets-of-all-time-by-donald-trump/\n",
    "2.https://www.kaggle.com/benhamner/clinton-trump-tweets\n",
    "\n",
    "- Number of observations:\n",
    "1.7300\n",
    "2. 3000+\n",
    "\n",
    "1-2 sentences describing the dataset. \n",
    "\n",
    "The dataset is an excel file of 7000 Trump tweets, with fields of date, time, tweet text, type of tweet (picture, text, link), hashtags, tweet ID, tweet URL, favorites and retweets. Similarly, we will also be using an excel file containing around 3000 tweets from both Trump and Clinton. \n",
    "\n",
    "If you plan to use multiple datasets, add 1-2 sentences about how you plan to combine these datasets.\n",
    "\n",
    "We plan on comparing Hillary Clinton’s archive of tweets versus Donald Trump’s archive of tweets to compare different buzzwords that each political party garners. We would not be combining the datasets themselves, but instead creating individual analyses for each of them, then comparing the results. That is, we plan to find the keywords for both Trump and Clinton, then compare these results with regards to their respective political parties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background & Prior Work\n",
    "\n",
    "Why is this question of interest, what background information led you to your hypothesis, and why is this important?\n",
    "\n",
    "Find some relevant prior work, and reference them. Even if you think you have a totally novel question, find the most similar prior work you can, and discuss how it relates to your project. \n",
    "\n",
    "References can be research publications, but they need not be: blogs, github repositories, company websites, etc., are viable references if they are relevant to your project.\n",
    "\n",
    "(2-3 paragraphs, including at least 2 references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your background and prior work here* \n",
    "\n",
    "We are interested in comparing these two datasets in order to determine which combination of sensational language garners more attention from the Twitterverse. We want to see what keywords engage each political party. \n",
    "\n",
    "As politically driven college students actively witnessing Trump’s regime, we want to understand on a critical level how his key phrases specifically target certain demographics in America when compared to Hillary Clinton. We researched other instances of those who also performed text analyses for Trump to determine how we could differentiate our research from other research that has already been conducted. Other data scientists were able to distinguish that non-hyperbolic tweets were conducted from iPhone (his staff), whereas every hyperbolic tweet were conducted through an Android (from Trump). There were also word frequency analyses conducted. Our research plans on parsing not exactly word frequencies, but phrases that garner the highest retweets. \n",
    "\n",
    "Through individual analysis, we hope to determine what phrases are considered the most important to modern day political parties. We intend to use conversational analysis algorithms to compare phrases from Trump’s tweets and compare them to Hillary Clinton. \n",
    "\n",
    "References (include a link):\n",
    "1) http://varianceexplained.org/r/trump-tweets/\n",
    "\n",
    "2)http://www.npr.org/2017/04/13/523709894/using-sentiment-analysis-to-understand-trumps-tweets\n",
    "\n",
    "3)https://www.washingtonpost.com/news/wonk/wp/2017/04/03/one-thing-trump-has-stopped-doing-on-twitter-since-inauguartion/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposed Methods\n",
    "\n",
    "What methods will you use to analyze your data?\n",
    "\n",
    "- How 'clean' is the data? To the extent that it requires cleaning, how will you do so?\n",
    "- How will you analyze the data? Be as specific as you can. Briefly mention any pre-processing steps that are required for your methods (for example, checking data distributions and performing any transformations that may be required). Include a brief outline of how you will apply your chosen method(s). \n",
    "- What do you plan to report? Briefly mention any key visualizations you plan to create, and/or the kind of result you will be able to report that addresses your question (this could be, for example, the outcome of some statistical test(s), prediction error on a model, a model fit parameter, etc.).\n",
    "- Include a list of packages you expect to use for you project. If you plan to use packages we have not used in class, add a very brief description about them (a few words is sufficient). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your proposed methods information here:*\n",
    "\n",
    "*Data Cleaning (2-3 sentences)*\n",
    "\n",
    "While the majority is well cleaned, there are a variety of random symbols throughout the data set that may interfere with the data analysis. Some of the symbols are separated by spaces, while others are embedded within the tweets themselves. We will need to parse through the data and remove any symbols that do not lie within valid characters that we specify.\n",
    "\n",
    "*Data Analysis (1-2 paragraphs)*\n",
    "\n",
    "First, since the second dataset contains tweets from both Hillary and Trump, we will strip the data so that only tweets from Hillary remain. This will give us two distinct datasets, one with Trump tweets and one with Hillary tweets. We will then save that stripped Clinton data into a separate dataset file and use this in our analysis and comparisons. We will be analyzing the frequency distribution of the text content of each tweet versus the retweets and favorites that it receives. To begin we will read in our .csv file as a pandas dataset. We can tokenize the tweets by using the function word_tokenize() and preserve symbols like “@”,URLS, and hashtags. We can use the most_common() method in collections.Counter() to find the N most commonly used words as well as their frequencies. Also, we will need to create a list of meaningless words to remove from our list of words. By preserving the hashtags and @ symbols we are able to see the most common hashtags and mentions in our tweets. We will then take the global average of the number of all retweets and likes for each candidate and then for each unique word, find the average number of retweets and likes for all tweets containing that word. We will then be able to see which words generate the highest amount of interest on average when compared to the global baseline. We can also then see how the frequency that a word is used relates to the reactions that the word generates. The next step is to find the same averages for groups of words and see how the average number of reactions changes. From here we will be able to construct a picture of which combinations of words generate the most reactions.\n",
    "\n",
    "*What to report (2-3 sentences)*\n",
    "\n",
    "We plan to report the most commonly used hashtags, mentions, and keywords in tweets and graph that in relation to the number of retweets and favourites that goes with each tweet. From this we hope to create a set of ‘optimal words and hashtags’ that each candidate tweet to generate the strongest reaction. There will definitely be outliers from meaningless words that are always contained in sentences that would cause prediction error\n",
    "\n",
    "Packages we plan to use:\n",
    "\n",
    "We expect to use Pandas and Numpy for basic data cleaning and analysis, while also using the package called “Natural Language Toolkit” for more in depth linguistic and lexical analysis. This package integrates various tools, such as functions to tokenize tweets and parse the strings, to analyze naturalistic human language that we will expect to find in the datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "What are the pitfalls and potential confounds of your data and/or methods? For example, how might biases in your data sources or analyses influence your interpretations? What will you do if you methods don't work and/or your hypotheses are wrong?\n",
    "\n",
    "(2-3 paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we may be more inclined to think that words such as “China”, “Mexico”, or “wall” may be more frequently referenced by Trump in his tweets, this may be due to media portrayal and the overall coverage of such statements by the media. Similarly, we may think that Hillary refers mostly to her campaign ideas in her tweets, but it could be the case that she in fact references other candidate’s ideas more often.. If our hypothesis is incorrect, we will have to consider what kind of bias may have let to the error and where we may have gone wrong in our thinking. Specifically we would need to reflect on why we associate certain words with the candidates when in fact it is the case that they do not tweet about them very often.\n",
    "\n",
    "For our actual analysis of the data, it is unlikely that our bias will affect our results since we are looking purely at which tweets/words are being reacted to, regardless of if that reaction was positive or negative. We will have to make sure that we eliminate words that will commonly be in the tweets but are not really substantial such as ‘the’, ‘of’, ‘and’, and ‘to’ so that only words that are substantive are considered. We believe the most difficult part of doing our analysis will be developing the algorithm that allows us to efficiently compare sets of words to determine which sets are more reacted to. It seems that it would be relatively straightforward to analyze the reaction to each word individually but it will be more challenging to compare all permutations of a set of N unique words efficiently.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
